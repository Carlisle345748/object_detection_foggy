import torch
import torch.nn as nn
from detectron2.layers import ShapeSpec


class DEB(nn.Module):
    """
    Depth Estimation Block: generate depth map with input feature map.
    Notes: the output depth map generated by up-sampling of the feature map(1/32H * 1/32W), has the same dimension
    as the ground truth depth map(H * W).
    """
    def __init__(self, input_shape: ShapeSpec):
        super(DEB, self).__init__()
        self.deb = nn.Sequential(
            nn.ConvTranspose2d(input_shape.channels, 256, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )
        self.deb.apply(self.init_weights)

    @classmethod
    @torch.no_grad()
    def init_weights(cls, model):
        if type(model) == nn.Conv2d:
            nn.init.kaiming_normal_(model.weight.data)

    def forward(self, x, gt_depth_map=None):
        gt_depth_map = torch.unsqueeze(gt_depth_map, 1)
        depth_map = self.deb(x)

        _, _, h1, w1 = depth_map.size()
        _, _, h, w = gt_depth_map.size() 
        if h1 != h or w1 != w:
            gt_depth_map = torch.nn.Upsample(size=(h1, w1), mode='bilinear')(gt_depth_map)

        if gt_depth_map is None:
            return None, {"depth": depth_map}

        depth_loss = self.reverse_huber_loss(depth_map, gt_depth_map)
        return {"depth_loss": depth_loss}, {"depth": depth_map}

    @staticmethod
    def reverse_huber_loss(y_pred, y_true):
        abs_diff = torch.abs(y_pred - y_true)
        c = 0.2 * torch.max(abs_diff)
        mask = abs_diff <= c
        rh_loss = torch.where(mask, abs_diff, (y_pred - y_true) ** 2 + c ** 2) / (2 * c)
        return torch.mean(rh_loss)


if __name__ == '__main__':
    test_input = torch.rand((4, 2, 32, 64))
    input_shape = ShapeSpec(channels=2)
    test_gt = torch.rand((4, 1024, 2048))

    test_deb = DEB(input_shape)
    loss, d_map = test_deb(test_input, test_gt)
    print(loss["depth_loss"], d_map["depth"].shape)
